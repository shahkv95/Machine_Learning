
        import numpy as np
        import tensorflow as tf
        import matplotlib.pyplot as plt
        np.random.seed(100)
        tf.set_random_seed(100)
        x = np.linspace(0, 50, 50)
        y = np.linspace(0, 50, 50)
        x += np.random.uniform(-4, 4, 50)
        y += np.random.uniform(-4, 4, 50)
        n = len(x)
     
        # Plot of Training Data
        plt.scatter(x, y)
        plt.xlabel('x')
        plt.xlabel('y')
        plt.title(\"Training Data\")
        plt.show()
        learning_rate = 0.003
        training_epochs = 1000
        X = tf.placeholder(\"float\")
        Y = tf.placeholder(\"float\")
        W = tf.Variable(np.random.randn(), name = \"W\")
        b = tf.Variable(np.random.randn(), name = \"b\")
        W = tf.Variable(np.random.randn(), name = \"W\")
        b = tf.Variable(np.random.randn(), name = \"b\")
        y_pred = tf.add(tf.multiply(X, W), b)
      
      
        # Mean Squared Error Cost Function
        cost = tf.reduce_sum(tf.pow(y_pred-Y, 2)) / (2 * n)
     
        # Gradient Descent Optimizer
        optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)
        init = tf.global_variables_initializer()
        with tf.Session() as sess:
        sess.run(init)
        for epoch in range(training_epochs):
        # Feeding each data point into the optimizer using Feed Dictionary
        for (_x, _y) in zip(x, y):
        sess.run(optimizer, feed_dict = {X : _x, Y : _y})
        # Displaying the result after every 50 epochs
        if (epoch + 1) % 50 == 0:
        # Calculating the cost
        c = sess.run(cost, feed_dict = {X : x, Y : y})
        print(\"Epoch\", (epoch + 1), \": cost =\", c, \"W =\", sess.run(W), \"b =\", sess.run(b))
        training_cost = sess.run(cost, feed_dict ={X: x, Y: y})
        weight = sess.run(W)
        tbias = sess.run(b)
        predictions = weight * x + bias

            Epoch 50 : cost = 5.7754993 W = 0.9868098 b = 0.111961626
            Epoch 100 : cost = 5.760742 W = 0.98565936 b = 0.16055892
            Epoch 150 : cost = 5.7472277 W = 0.984554 b = 0.20726101
            Epoch 200 : cost = 5.734854 W = 0.9834918 b = 0.25214157
            Epoch 250 : cost = 5.7235336 W = 0.98247087 b = 0.29527125
            Epoch 300 : cost = 5.713177 W = 0.9814898 b = 0.33671907
            Epoch 350 : cost = 5.703711 W = 0.980547 b = 0.3765502
            Epoch 400 : cost = 5.6950607 W = 0.9796411 b = 0.41482806
            Epoch 450 : cost = 5.687162 W = 0.9787704 b = 0.45161238
            Epoch 500 : cost = 5.6799536 W = 0.97793365 b = 0.48696217
            Epoch 550 : cost = 5.673377 W = 0.9771296 b = 0.5209336
            Epoch 600 : cost = 5.6673846 W = 0.9763569 b = 0.5535794
            Epoch 650 : cost = 5.6619253 W = 0.97561425 b = 0.5849517
            Epoch 700 : cost = 5.6569567 W = 0.97490066 b = 0.6151011
            Epoch 750 : cost = 5.6524386 W = 0.9742149 b = 0.6440746
            Epoch 800 : cost = 5.648333 W = 0.9735558 b = 0.6719181
            Epoch 850 : cost = 5.6446066 W = 0.97292256 b = 0.6986735
            Epoch 900 : cost = 5.641229 W = 0.9723139 b = 0.7243879
            Epoch 950 : cost = 5.6381674 W = 0.97172904 b = 0.74909806
            Epoch 1000 : cost = 5.6354 W = 0.97116697 b = 0.77284586
         

        # Plotting the Results
        plt.plot(x, y, 'ro', label ='Original data')
        plt.plot(x, predictions, label ='Fitted line')
        plt.title('Linear Regression Result')
        plt.legend()
        plt.show()
      

